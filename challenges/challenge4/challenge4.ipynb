{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Advanced RAG with Azure AI Document intelligence\n",
    "\n",
    "Many documents in  real scenario, are not just text, they are a combination of text, images, tables, etc. In this step, you will create a more advanced RAG application able to deal with this kind of documents.\n",
    "For this reason, you will use Azure AI Document Intelligence to extract the text, images, and tables from the documents and use them as input for the RAG model.\n",
    "\n",
    "To achieve this, we will build on top of the langchain framework enhancing the `Document Loader` and `Text Splitters` to deal with images and tables.\n",
    "In the code repositiory, you have already the enhanced version of the `Document Loader` and `Text Splitters` that you can use. They are included in two different python modules: `doc_intelligence.py` and `ingestion.py`.\n",
    "\n",
    "You can now use these libraries to create your advanced RAG.\n",
    "\n",
    "We provided already the libraries and the Environment variables required (you need just to populate them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureAIDocumentIntelligenceLoader: <class 'its_a_rag.doc_intelligence.AzureAIDocumentIntelligenceLoader'>\n",
      "ingestion module: <module 'its_a_rag.ingestion' from '/workspaces/itsarag/lib/its_a_rag/ingestion.py'>\n"
     ]
    }
   ],
   "source": [
    "import sys, os, dotenv\n",
    "dotenv.load_dotenv(override=True)\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "# Setup environment\n",
    "\n",
    "# OpenAI\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_EMBEDDING\")\n",
    "# Azure Search\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "# Azure AI Document Intelligence\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION= os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\")\n",
    "# Azure Blob Storage\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONTAINER = os.getenv(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_STORAGE_FOLDER = os.getenv(\"AZURE_STORAGE_FOLDER\")\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n",
    "\n",
    "# Custom Libraries\n",
    "from its_a_rag.doc_intelligence import AzureAIDocumentIntelligenceLoader\n",
    "from its_a_rag import ingestion\n",
    "\n",
    "# Check if custom libraries loaded successfully\n",
    "print(\"AzureAIDocumentIntelligenceLoader:\", AzureAIDocumentIntelligenceLoader)\n",
    "print(\"ingestion module:\", ingestion)\n",
    "\n",
    "# Define the questions list (if you are using your own dataset you need to change this list)\n",
    "QUESTIONS = [\n",
    "  \"What are the revenues of GOOGLE in the year 2009?\",\n",
    "  \"What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?\",\n",
    "  \"Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?\",\n",
    "  \"Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?\",\n",
    "  \"Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\",\n",
    "  \"What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?\",\n",
    "  \"What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?\",\n",
    "  \"Can you buy 10 shares of APPLE for me?\"\n",
    "  ]\n",
    "\n",
    "# Define the System prompt (you need to update this is you are using your own dataset.)\n",
    "system_prompt = \"\"\" You are a financial assistant tasked with answering questions related to the financial results of major technology companies listed on NASDAQ, \\n\n",
    "specifically Microsoft (MSFT), Alphabet Inc. (GOOGL), Nvidia (NVDA), Apple Inc. (AAPL), and Amazon (AMZN). \\n\n",
    "if you don't find the answer in the context, just say `I don't know.`\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vector store, the embeddings client and the OpenAI Chat client\n",
    "\n",
    "Let's start creating the vector store and the embeddings client. Because we need a custom index to store the information in the way so that our retriever wil be able to get it, we have a custom function for that (create_multimodal_vectore_store).\n",
    "For the OpenAI Chat client we will simply use the one offered by langchain framework as in the Step 3 of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index for Azure Search store and Embedding (using the custom function create_multimodal_vector_store)\n",
    "# NOTE: Remember to create the new index in Azure Search called \"itsarag-ch4-001\"\n",
    "vector_store, embeddings = ingestion.create_multimodal_vector_store(\n",
    "    index_name=\"itsarag-ch4-001\",\n",
    "    azure_openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_openai_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_openai_embedding_deployment=AZURE_OPENAI_EMBEDDING,\n",
    "    azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    azure_search_api_key=AZURE_SEARCH_API_KEY\n",
    ")\n",
    "\n",
    "# Create the Azure OpenAI Chat Client\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    model=AZURE_OPENAI_MODEL,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Phase\n",
    "\n",
    "As always the first step is to index the documents:\n",
    "the high level steps are:\n",
    "\n",
    "- Set Folder Path: Assign the local folder path to the variable folder.\n",
    "- List Files: Create a list of files in the specified folder.\n",
    "- Get Full Paths: Convert the list of file names to their full paths.\n",
    "- Iterate Over Files: Loop through each file in the list.\n",
    "    - Extract File Name: Extract the file name from the full path (this is required for the document loader).\n",
    "    - Load Document: Use AzureAIDocumentIntelligenceLoader to load the document with specified API credentials and settings (remember to use pre-built layout as model and the latest API version)\n",
    "    - Split Document: Split the loaded document using a custom advanced text splitter.\n",
    "    - Store Document: Add the processed documents to a multimodal vector store (using the add_documents method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  ../../data/fsi/pdf/2023 FY NVDA.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY NVDA.pdf...\n",
      "Updating figure description 0...\n",
      "Updating figure description 1...\n",
      "Updating figure description 2...\n",
      "Updating figure description 3...\n",
      "Updating figure description 4...\n",
      "Updating figure description 5...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY GOOGL.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY GOOGL.pdf...\n",
      "Updating figure description 0...\n",
      "Updating figure description 1...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY MSFT.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY MSFT.pdf...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY APPL.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY APPL.pdf...\n",
      "Updating figure description 0...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY AMZN.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY AMZN.pdf...\n"
     ]
    }
   ],
   "source": [
    "# Index\n",
    "\n",
    "# Index: Load files\n",
    "\n",
    "# Get list of files in a local folder that start with \"2023\"\n",
    "folder = \"../../data/fsi/pdf\"\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(\"2023\")]\n",
    "files = [os.path.join(folder, f) for f in files]\n",
    "\n",
    "# For each file\n",
    "for file in files:\n",
    "    # Get the file name\n",
    "    pdf_file_name = os.path.basename(file)\n",
    "    # Index : Load the file and create a document\n",
    "    print(\"Processing: \", file)\n",
    "    loader = AzureAIDocumentIntelligenceLoader(\n",
    "        file_path=file,\n",
    "        api_key=AZURE_DOCUMENT_INTELLIGENCE_API_KEY,\n",
    "        api_endpoint=AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "        api_version=AZURE_DOCUMENT_INTELLIGENCE_API_VERSION,\n",
    "        api_model=\"prebuilt-layout\"\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Index : Split (using advanced text splitter from the custom library)\n",
    "    docs_split = ingestion.advanced_text_splitter(docs, pdf_file_name)\n",
    "\n",
    "    # Index : Store (add_documents from the custom library)\n",
    "    vector_store.add_documents(docs_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Phase\n",
    "\n",
    "The next step is to create a retriever for the documents based on the user query.\n",
    "You should use the following parameters:\n",
    "- Search Type: Hybrid\n",
    "- number of results: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve  (as_retriever)\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"hybrid\",\n",
    "    k = 30  # Retrieve top 30 results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Phase\n",
    "\n",
    "The final step is to generate the answer using the RAG model.\n",
    "We will create a Langchain chain with the following steps:\n",
    " - Retrieve the docs and get the image description if the doc matedata is an image (with get_image_description function - RunnableLambda), then pass the context and question (using RunnablePassthrough) to the next phase\n",
    " - Use the advanced multimodal Prompt function to append system messages, the context including the text, the image (if present) and the question - check RannableLambda method also here.\n",
    " - Use the OpenAI model to generate the answer\n",
    " - Parse the output and return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "\n",
    "# RAG pipeline\n",
    "\n",
    "# Step 1: Retrieve relevant documents and extract image descriptions/texts\n",
    "def retrieve_and_describe(query):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    context = ingestion.get_image_description(docs)\n",
    "    return {\"context\": context, \"question\": query}\n",
    "\n",
    "# Step 2: Generate the multimodal prompt\n",
    "def build_multimodal_prompt(inputs):\n",
    "    return ingestion.multimodal_prompt(inputs)\n",
    "\n",
    "# Step 3: Build the Langchain chain\n",
    "chain_multimodal_rag = (\n",
    "    RunnableLambda(retrieve_and_describe)  # Retrieve docs and extract context\n",
    "    | RunnableLambda(build_multimodal_prompt)  # Build prompt with system, context, question\n",
    "    | llm  # Azure OpenAI Chat client\n",
    "    | StrOutputParser()  # Parse output\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Solution\n",
    "\n",
    "You can test the solution by providing a question and checking the answer generated by the RAG model (invoke the Langchain chain).\n",
    "\n",
    "Try to get answer for the following questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: What are the revenues of GOOGLE in the year 2009?\n",
      "I don't know. The provided context does not include Google's revenues for the year 2009.\n",
      "--------------------------------------------------\n",
      "QUESTION: What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?\n",
      "In 2022, Alphabet Inc. reported revenues of **$282.8 billion** and an operating margin of **26%**. Compared to 2021, revenues increased by **9.8%** (from $257.6 billion), while the operating margin decreased slightly from **30.5%** in 2021. \n",
      "\n",
      "In 2023, revenues grew further to **$307.4 billion**, and the operating margin improved to **27%**, reflecting a 1% increase from 2022.\n",
      "--------------------------------------------------\n",
      "QUESTION: Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?\n",
      "\n",
      "Based on the provided context, here is a table summarizing the total revenue for Alphabet, NVIDIA, Microsoft, and Apple in 2023:\n",
      "\n",
      "| Company   | Total Revenue (2023) |\n",
      "|-----------|-----------------------|\n",
      "| Alphabet  | $307.4 billion       |\n",
      "| NVIDIA    | $60.9 billion        |\n",
      "| Microsoft | $211.9 billion       |\n",
      "| Apple     | $383.3 billion       |\n",
      "--------------------------------------------------\n",
      "QUESTION: Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?\n",
      "\n",
      "### Fiscal Year 2023 Highlights:\n",
      "\n",
      "#### **Apple Inc.**\n",
      "- Total net sales: $383.3 billion.\n",
      "- Net income: $97.0 billion.\n",
      "- Net sales decreased by 3% compared to 2022, primarily due to lower sales of Mac and iPhone, partially offset by higher Services revenue.\n",
      "- Fiscal year 2023 spanned 53 weeks.\n",
      "\n",
      "#### **Microsoft Corporation**\n",
      "- Microsoft Cloud revenue: $111.6 billion, up 22%.\n",
      "- Office Commercial products and cloud services revenue: Increased 10%.\n",
      "- Dynamics products and cloud services revenue: Increased 16%, driven by Dynamics 365 growth of 24%.\n",
      "- Server products and cloud services revenue: Increased 19%, driven by Azure and other cloud services growth of 29%.\n",
      "- Windows OEM revenue: Decreased 25%.\n",
      "- Devices revenue: Decreased 24%.\n",
      "- Total revenue: $211.9 billion.\n",
      "\n",
      "#### **NVIDIA Corporation**\n",
      "- Total revenue: $26.97 billion.\n",
      "- Data Center revenue: Up 217%.\n",
      "- Gaming revenue: Up 15%.\n",
      "- Automotive revenue: Up 21%.\n",
      "- Gross margin: Increased to 72.7% from 56.9%.\n",
      "- Net income: $4.37 billion, up 581%.\n",
      "- Significant growth in AI and generative AI platforms, including NVIDIA Hopper and Grace Hopper processors.\n",
      "--------------------------------------------------\n",
      "QUESTION: Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\n",
      "\n",
      "Yes, Apple repurchased common stock in 2023. Below is a table summarizing the repurchase activity:\n",
      "\n",
      "| **Date/Period**                  | **Number of Shares Repurchased (in millions)** | **Value (in billions USD)** |\n",
      "|----------------------------------|-----------------------------------------------|-----------------------------|\n",
      "| Fiscal Year 2023 (Total)         | 471                                           | $76.6                      |\n",
      "| April 1, 2023 - April 30, 2023   | 5.01                                          | $1.44                      |\n",
      "| May 1, 2023 - May 31, 2023       | 5.36                                          | $1.68                      |\n",
      "| June 1, 2023 - June 30, 2023     | 4.41                                          | $1.47                      |\n",
      "| July 2, 2023 - August 5, 2023    | 33.86                                         | $6.49                      |\n",
      "| August 6, 2023 - September 2, 2023 (ASRs) | 22.09                                  | $5.00 (upfront payment)    |\n",
      "| August 6, 2023 - September 2, 2023 (Open Market) | 30.30                          | $5.42                      |\n",
      "| September 3, 2023 - September 30, 2023 | 20.35                                   | $3.59                      |\n",
      "\n",
      "Note: The total value excludes excise tax under the Inflation Reduction Act of 2022.\n",
      "--------------------------------------------------\n",
      "QUESTION: What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The value of the cumulative 5-year total return of Alphabet Class A at December 2022 is approximately **$200**, as inferred from the red line in the provided chart.\n",
      "--------------------------------------------------\n",
      "QUESTION: What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?\n",
      "\n",
      "\n",
      "I don't know the stock prices of Apple, NVIDIA, and Microsoft on July 23, 2024, as the provided context does not include this information.\n",
      "--------------------------------------------------\n",
      "QUESTION: Can you buy 10 shares of APPLE for me?\n",
      "\n",
      "I cannot buy shares for you. You would need to contact a licensed broker or use a trading platform to purchase 10 shares of Apple Inc. (AAPL).\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the solution\n",
    "for QUESTION in QUESTIONS:\n",
    "    print(f\"QUESTION: {QUESTION}\")\n",
    "    print(chain_multimodal_rag.invoke(QUESTION))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
